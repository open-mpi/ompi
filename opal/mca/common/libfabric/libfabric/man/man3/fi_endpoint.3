.TH fi_endpoint 3 "2015\-02\-27" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
.SH NAME
.PP
fi_endpoint - Fabric endpoint operations
.TP
.B fi_endpoint / fi_scalable_ep / fi_passive_ep / fi_close
Allocate or close an endpoint.
.RS
.RE
.TP
.B fi_ep_bind
Associate an endpoint with an event queue, completion queue, counter,
address vector, or memory region
.RS
.RE
.TP
.B fi_scalable_ep_bind
Associate a scalable endpoint with an address vector
.RS
.RE
.TP
.B fi_pep_bind
Associate a passive endpoint with an event queue
.RS
.RE
.TP
.B fi_enable
Transitions an endpoint into an active state.
.RS
.RE
.TP
.B fi_cancel
Cancel a pending asynchronous data transfer
.RS
.RE
.TP
.B fi_alias
Create an alias to the endpoint
.RS
.RE
.TP
.B fi_control
Control endpoint operation.
.RS
.RE
.TP
.B fi_getopt / fi_setopt
Get or set endpoint options.
.RS
.RE
.TP
.B fi_rx_context / fi_tx_context / fi_srx_context / fi_stx_context
Open a transmit or receive context.
.RS
.RE
.TP
.B fi_rx_size_left / fi_tx_size_left
Query the lower bound on how many RX/TX operations may be posted without
an operation returning -FI_EAGAIN.
.RS
.RE
.SH SYNOPSIS
.IP
.nf
\f[C]
#include\ <rdma/fabric.h>

#include\ <rdma/fi_endpoint.h>

int\ fi_endpoint(struct\ fid_domain\ *domain,\ struct\ fi_info\ *info,
\ \ \ \ struct\ fid_ep\ **ep,\ void\ *context);

int\ fi_scalable_ep(struct\ fid_domain\ *domain,\ struct\ fi_info\ *info,
\ \ \ \ struct\ fid_ep\ **sep,\ void\ *context);

int\ fi_passive_ep(struct\ fi_fabric\ *fabric,\ struct\ fi_info\ *info,
\ \ \ \ struct\ fid_pep\ **pep,\ void\ *context);

int\ fi_tx_context(struct\ fid_ep\ *sep,\ int\ index,
\ \ \ \ struct\ fi_tx_attr\ *attr,\ struct\ fid_ep\ **tx_ep,
\ \ \ \ void\ *context);

int\ fi_rx_context(struct\ fid_ep\ *sep,\ int\ index,
\ \ \ \ struct\ fi_rx_attr\ *attr,\ struct\ fid_ep\ **rx_ep,
\ \ \ \ void\ *context);

int\ fi_stx_context(struct\ fid_domain\ *domain,
\ \ \ \ struct\ fi_tx_attr\ *attr,\ struct\ fid_stx\ **stx,
\ \ \ \ void\ *context);

int\ fi_srx_context(struct\ fid_domain\ *domain,
\ \ \ \ struct\ fi_rx_attr\ *attr,\ struct\ fid_ep\ **rx_ep,
\ \ \ \ void\ *context);

int\ fi_close(struct\ fid\ *ep);

int\ fi_ep_bind(struct\ fid_ep\ *ep,\ struct\ fid\ *fid,\ uint64_t\ flags);

int\ fi_scalable_ep_bind(struct\ fid_ep\ *sep,\ struct\ fid\ *fid,\ uint64_t\ flags);

int\ fi_pep_bind(struct\ fid_pep\ *pep,\ struct\ fid\ *fid,\ uint64_t\ flags);

int\ fi_enable(struct\ fid_ep\ *ep);

int\ fi_cancel(struct\ fid_ep\ *ep,\ void\ *context);

int\ fi_alias(struct\ fid_ep\ *ep,\ fid_t\ *alias_ep,\ uint64_t\ flags);

int\ fi_control(struct\ fid\ *ep,\ int\ command,\ void\ *arg);

int\ fi_getopt(struct\ fid_\ *ep,\ int\ level,\ int\ optname,
\ \ \ \ void\ *optval,\ size_t\ *optlen);

int\ fi_setopt(struct\ fid\ *ep,\ int\ level,\ int\ optname,
\ \ \ \ const\ void\ *optval,\ size_t\ optlen);

ssize_t\ fi_rx_size_left(struct\ fid_ep\ *ep);

ssize_t\ fi_tx_size_left(struct\ fid_ep\ *ep);
\f[]
.fi
.SH ARGUMENTS
.PP
\f[I]fid\f[] : On creation, specifies a fabric or access domain.
On bind, identifies the event queue, completion queue or address vector
to bind to the endpoint.
.PP
\f[I]info\f[] : Details about the fabric interface endpoint to be
opened, obtained from fi_getinfo.
.PP
\f[I]ep\f[] : A fabric endpoint.
.PP
\f[I]sep\f[] : A scalable fabric endpoint.
.PP
\f[I]pep\f[] : A passive fabric endpoint.
.PP
\f[I]fid\f[] : Fabric identifier of an associated resource.
.PP
\f[I]context\f[] : Context associated with the endpoint or asynchronous
operation.
.PP
\f[I]flags\f[] : Additional flags to apply to the operation.
.PP
\f[I]command\f[] : Command of control operation to perform on endpoint.
.PP
\f[I]arg\f[] : Optional control argument
.PP
\f[I]level\f[] : Protocol level at which the desired option resides.
.PP
\f[I]optname\f[] : The protocol option to read or set.
.PP
\f[I]optval\f[] : The option value that was read or to set.
.PP
\f[I]optlen\f[] : The size of the optval buffer.
.SH DESCRIPTION
.PP
Endpoints are transport level communication portals.
There are two types of endpoints: active and passive.
Passive endpoints belong to a fabric domain and are used to listen for
incoming connection requests.
Active endpoints belong to access domains and can perform data
transfers.
.PP
Active endpoints may be connection-oriented or connectionless, and may
provide data reliability.
The data transfer interfaces -- messages (fi_msg), tagged messages
(fi_tagged), RMA (fi_rma), and atomics (fi_atomic) -- are associated
with active endpoints.
In basic configurations, an active endpoint has transmit and receive
queues.
In general, operations that generate traffic on the fabric are posted to
the transmit queue.
This includes all RMA and atomic operations, along with sent messages
and sent tagged messages.
Operations that post buffers for receiving incoming data are submitted
to the receive queue.
.PP
Active endpoints are created in the disabled state.
They must transition into an enabled state before accepting data
transfer operations, including posting of receive buffers.
The fi_enable call is used to transition an endpoint into an active
enabled state.
The fi_connect and fi_accept calls will also transition an endpoint into
the enabled state, if it is not already active.
.PP
In order to transition an endpoint into an enabled state, it must be
bound to one or more fabric resources.
An endpoint that will generate asynchronous completions, either through
data transfer operations or communication establishment events, must be
bound to the appropriate completion queues or event queues before being
enabled.
.PP
Once an endpoint has been activated, it may be associated with memory
regions and address vectors.
Receive buffers may be posted to it, and calls may be made to connection
establishment routines.
Connectionless endpoints may also perform data transfers.
.PP
The behavior of an endpoint may be adjusted by setting its control data
and protocol options.
This allows the underlying provider to redirect function calls to
implementations optimized to meet the desired application behavior.
.SS fi_endpoint / fi_passive_ep / fi_scalable_ep
.PP
fi_endpoint allocates a new active endpoint.
fi_passive_ep allocates a new passive endpoint.
fi_scalable_ep allocates a scalable endpoint.
The properties and behavior of the endpoint are defined based on the
provided struct fi_info.
See fi_getinfo for additional details on fi_info.
fi_info flags that control the operation of an endpoint are defined
below.
See section SCALABLE ENDPOINTS.
.PP
If an active endpoint is associated with a connection request, the
fi_info connreq must reference the corresponding request.
.SS fi_close
.PP
Closes an endpoint and release all resources associated with it.
.PP
When closing a scalable endpoint, there must be no opened transmit
contexts, or receive contexts associated with the scalable endpoint.
If resources are still associated with the scalable endpoint when
attempting to close, the call will return -FI_EBUSY.
.PP
Outstanding operations posted to the endpoint when fi_close is called
will be discarded.
Discarded operations will silently be dropped, with no completions
reported.
Additionally, a provider may discard previously completed operations
from the associated completion queue(s).
The behavior to discard completed operations is provider specific.
.SS fi_ep_bind
.PP
fi_ep_bind is used to associate an endpoint with hardware resources.
The common use of fi_ep_bind is to direct asynchronous operations
associated with an endpoint to a completion queue.
An endpoint must be bound with CQs capable of reporting completions for
any asynchronous operation initiated on the endpoint.
This is true even for endpoints which are configured to suppress
successful completions, in order that operations that complete in error
may be reported to the user.
For passive endpoints, this requires binding the endpoint with an EQ
that supports the communication management (CM) domain.
.PP
An active endpoint may direct asynchronous completions to different CQs,
based on the type of operation.
This is specified using fi_ep_bind flags.
The following flags may be used separately or OR\[aq]ed together when
binding an endpoint to a completion domain CQ.
.PP
\f[I]FI_TRANSMIT\f[] : Directs the completion of outbound data transfer
requests to the specified completion queue.
This includes send message, RMA, and atomic operations.
The FI_SEND flag may be used interchangeably.
.PP
\f[I]FI_RECV\f[] : Directs the notification of inbound data transfers to
the specified completion queue.
This includes received messages.
.PP
\f[I]FI_COMPLETION\f[] : By default, data transfer operations generate
completion entries into a completion queue after they have successfully
completed.
Applications can use this bind flag to selectively enable when
completions are generated.
If FI_COMPLETION is specified, data transfer operations will not
generate entries for successful completions unless FI_COMPLETION is set
as an operational flag for the given operation.
FI_COMPLETION must be OR\[aq]ed with FI_SEND and/or FI_RECV flags.
.PP
When set the user must determine when a request that does NOT have
FI_COMPLETION set has completed indirectly, usually based on the
completion of a subsequent operation.
Use of this flag may improve performance by allowing the provider to
avoid writing a completion entry for every operation.
.PP
Example: An application can selectively generate send completions by
using the following general approach:
.IP
.nf
\f[C]
\ \ fi_tx_attr::op_flags\ =\ 0;\ //\ default\ -\ no\ completion
\ \ fi_ep_bind(ep,\ cq,\ FI_SEND\ |\ FI_COMPLETION);
\ \ fi_send(ep,\ ...);\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ //\ no\ completion
\ \ fi_sendv(ep,\ ...);\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ //\ no\ completion
\ \ fi_sendmsg(ep,\ ...,\ FI_COMPLETION);\ //\ completion!
\f[]
.fi
.PP
Example: An application can selectively disable send completions by
modifying the operational flags:
.IP
.nf
\f[C]
\ \ fi_tx_attr::op_flags\ =\ FI_COMPLETION;\ //\ default\ -\ completion
\ \ fi_ep_bind(ep,\ cq,\ FI_SEND\ |\ FI_COMPLETION);
\ \ fi_send(ep,\ ...);\ \ \ \ \ \ \ //\ completion
\ \ fi_sendv(ep,\ ...);\ \ \ \ \ \ //\ completion
\ \ fi_sendmsg(ep,\ ...,\ 0);\ //\ no\ completion!
\f[]
.fi
.PP
An endpoint may also, or instead, be bound to a fabric counter.
When binding an endpoint to a counter, the following flags may be
specified.
.PP
\f[I]FI_SEND\f[] : Increments the specified counter whenever a
successful message is transferred over the endpoint.
Sent messages include both tagged and normal message operations.
.PP
\f[I]FI_RECV\f[] : Increments the specified counter whenever a
successful message is received over the endpoint.
Received messages include both tagged and normal message operations.
.PP
\f[I]FI_READ\f[] : Increments the specified counter whenever a
successful RMA read or atomic fetch operation is initiated from the
endpoint.
.PP
\f[I]FI_WRITE\f[] : Increments the specified counter whenever a
successful RMA write or atomic operation is initiated from the endpoint.
.PP
\f[I]FI_REMOTE_READ\f[] : Increments the specified counter whenever a
successful RMA read or atomic fetch operation is initiated from a remote
endpoint that targets the given endpoint.
.PP
\f[I]FI_REMOTE_WRITE\f[] : Increments the specified counter whenever a
successful RMA write or atomic operation is initiated from a remote
endpoint that targets the given endpoint.
.PP
Connectionless endpoints must be bound to a single address vector.
If an endpoint is using a shared transmit and/or receive context, the
shared contexts must be bound to the endpoint.
CQs, counters, AV, and shared contexts must be bound to endpoints before
they are enabled.
.SS fi_scalable_ep_bind
.PP
fi_scalable_ep_bind is used to associate a scalable endpoint with an
address vector.
See section on SCALABLE ENDPOINTS.
A scalable endpoint has a single transport level address and can support
multiple transmit and receive contexts.
The transmit and receive contexts share the transport-level address.
Address vectors that are bound to scalable endpoints are implicitly
bound to any transmit or receive contexts created using the scalable
endpoint.
.SS fi_enable
.PP
This call transitions the endpoint into an enabled state.
An endpoint must be enabled before it may be used to perform data
transfers.
Enabling an endpoint typically results in hardware resources being
assigned to it.
.PP
Calling connect or accept on an endpoint will implicitly enable an
endpoint if it has not already been enabled.
.SS fi_cancel
.PP
fi_cancel attempts to cancel an outstanding asynchronous operation.
The endpoint must have been configured to support cancelable operations
-- see FI_CANCEL flag -- in order for this call to succeed.
Canceling an operation causes the fabric provider to search for the
operation and, if it is still pending, complete it as having been
canceled.
If multiple outstanding operations match the context parameter, only one
will be canceled.
In this case, the operation which is canceled is provider specific.
The cancel operation will complete within a bounded period of time.
.SS fi_alias
.PP
This call creates an alias to the specified endpoint.
Conceptually, an endpoint alias provides an alternate software path from
the application to the underlying provider hardware.
Applications configure an alias endpoint with data transfer flags,
specified through the fi_alias call.
Typically, the data transfer flags will be different than those assigned
to the actual endpoint.
The alias mechanism allows a single endpoint to have multiple optimized
software interfaces.
All allocated aliases must be closed for the underlying endpoint to be
released.
.SS fi_control
.PP
The control operation is used to adjust the default behavior of an
endpoint.
It allows the underlying provider to redirect function calls to
implementations optimized to meet the desired application behavior.
As a result, calls to fi_ep_control must be serialized against all other
calls to an endpoint.
.PP
The base operation of an endpoint is selected during creation using
struct fi_info.
The following control commands and arguments may be assigned to an
endpoint.
.PP
**FI_GETOPSFLAG -- uint64_t \f[I]flags\f[]* : Used to retrieve the
current value of flags associated with data transfer operations
initiated on the endpoint.
See below for a list of control flags.
.PP
**FI_SETOPSFLAG -- uint64_t \f[I]flags\f[]* : Used to change the data
transfer operation flags associated with an endpoint.
The FI_READ, FI_WRITE, FI_SEND, FI_RECV flags indicate the type of data
transfer that the flags should apply to, with other flags OR\[aq]ed in.
Valid control flags are defined below.
.SS fi_getopt / fi_setopt
.PP
Endpoint protocol operations may be retrieved using fi_getopt or set
using fi_setopt.
Applications specify the level that a desired option exists, identify
the option, and provide input/output buffers to get or set the option.
fi_setopt provides an application a way to adjust low-level protocol and
implementation specific details of an endpoint.
.PP
The following option levels and option names and parameters are defined.
.PP
\f[I]FI_OPT_ENDPOINT\f[]
.IP \[bu] 2
\f[I]FI_OPT_MIN_MULTI_RECV - size_t\f[] : Defines the minimum receive
buffer space available when the receive buffer is automatically freed
(see FI_MULTI_RECV).
Modifying this value is only guaranteed to set the minimum buffer space
needed on receives posted after the value has been changed.
It is recommended that applications that want to override the default
MIN_MULTI_RECV value set this option before enabling the corresponding
endpoint.
.IP \[bu] 2
\f[I]FI_OPT_CM_DATA_SIZE - size_t\f[] : Defines the size of available
space in CM messages for user-defined data.
This value limits the amount of data that applications can exchange
between peer endpoints using the fi_connect, fi_accept, and fi_reject
operations.
This option is read only.
.SS fi_rx_size_left
.PP
The fi_rx_size_left call returns a lower bound on the number of receive
operations that may be posted to the given endpoint without that
operation returning -FI_EAGAIN.
Depending on the specific details of the subsequently posted receive
operations (e.g., number of iov entries, which receive function is
called, etc.)
, it may be possible to post more receive operations than originally
indicated by fi_rx_size_left.
.SS fi_tx_size_left
.PP
The fi_tx_size_left call returns a lower bound on the number of transmit
operations that may be posted to the given endpoint without that
operation returning -FI_EAGAIN.
Depending on the specific details of the subsequently posted transmit
operations (e.g., number of iov entries, which transmit function is
called, etc.)
, it may be possible to post more transmit operations than originally
indicated by fi_tx_size_left.
.SH ENDPOINT ATTRIBUTES
.PP
The fi_ep_attr structure defines the set of attributes associated with
an endpoint.
.IP
.nf
\f[C]
struct\ fi_ep_attr\ {
\ \ \ \ enum\ fi_ep_type\ ep_type;
\ \ \ \ uint32_t\ \ \ \ \ \ \ \ protocol;
\ \ \ \ uint32_t\ \ \ \ \ \ \ \ protocol_version;
\ \ \ \ size_t\ \ \ \ \ \ \ \ \ \ max_msg_size;
\ \ \ \ size_t\ \ \ \ \ \ \ \ \ \ msg_prefix_size;
\ \ \ \ size_t\ \ \ \ \ \ \ \ \ \ max_order_raw_size;
\ \ \ \ size_t\ \ \ \ \ \ \ \ \ \ max_order_war_size;
\ \ \ \ size_t\ \ \ \ \ \ \ \ \ \ max_order_waw_size;
\ \ \ \ uint64_t\ \ \ \ \ \ \ \ mem_tag_format;
\ \ \ \ uint64_t\ \ \ \ \ \ \ \ msg_order;
\ \ \ \ uint64_t\ \ \ \ \ \ \ \ comp_order;
\ \ \ \ size_t\ \ \ \ \ \ \ \ \ \ tx_ctx_cnt;
\ \ \ \ size_t\ \ \ \ \ \ \ \ \ \ rx_ctx_cnt;
};
\f[]
.fi
.SS type - Endpoint Type
.PP
If specified, indicates the type of fabric interface communication
desired.
Supported types are:
.PP
\f[I]FI_EP_UNSPEC\f[] : The type of endpoint is not specified.
This is usually provided as input, with other attributes of the endpoint
or the provider selecting the type.
.PP
\f[I]FI_EP_MSG\f[] : Provides a reliable, connection-oriented data
transfer service with flow control that maintains message boundaries.
.PP
\f[I]FI_EP_DGRAM\f[] : Supports a connectionless, unreliable datagram
communication.
Message boundaries are maintained, but the maximum message size may be
limited to the fabric MTU.
Flow control is not guaranteed.
.PP
\f[I]FI_EP_RDM\f[] : Reliable datagram message.
Provides a reliable, unconnected data transfer service with flow control
that maintains message boundaries.
.SS Protocol
.PP
Specifies the low-level end to end protocol employed by the provider.
A matching protocol must be used by communicating endpoints to ensure
interoperability.
The following protocol values are defined.
Provider specific protocols are also allowed.
Provider specific protocols will be indicated by having the upper bit of
the protocol value set to one.
.PP
\f[I]FI_PROTO_UNSPEC\f[] : The protocol is not specified.
This is usually provided as input, with other attributes of the socket
or the provider selecting the actual protocol.
.PP
\f[I]FI_PROTO_RDMA_CM_IB_RC\f[] : The protocol runs over Infiniband
reliable-connected queue pairs, using the RDMA CM protocol for
connection establishment.
.PP
\f[I]FI_PROTO_IWARP\f[] : The protocol runs over the Internet wide area
RDMA protocol transport.
.PP
\f[I]FI_PROTO_IB_UD\f[] : The protocol runs over Infiniband unreliable
datagram queue pairs.
.PP
\f[I]FI_PROTO_PSMX\f[] : The protocol is based on an Intel proprietary
protocol known as PSM, performance scaled messaging.
PSMX is an extended version of the PSM protocol to support the libfabric
interfaces.
.PP
\f[I]FI_PROTO_UDP\f[] : The protocol sends and receives UDP datagrams.
For example, an endpoint using \f[I]FI_PROTO_UDP\f[] will be able to
communicate with a remote peer that is using Berkeley
\f[I]SOCK_DGRAM\f[] sockets using \f[I]IPPROTO_UDP\f[].
.PP
\f[I]FI_PROTO_SOCK_TCP\f[] : The protocol is layered over TCP packets.
.SS protocol_version - Protocol Version
.PP
Identifies which version of the protocol is employed by the provider.
The protocol version allows providers to extend an existing protocol, by
adding support for additional features or functionality for example, in
a backward compatible manner.
Providers that support different versions of the same protocol should
inter-operate, but only when using the capabilities defined for the
lesser version.
.SS max_msg_size - Max Message Size
.PP
Defines the maximum size for an application data transfer as a single
operation.
.SS msg_prefix_size - Message Prefix Size
.PP
Specifies the size of any required message prefix buffer space.
This field will be 0 unless the FI_MSG_PREFIX mode is enabled.
If msg_prefix_size is > 0 the specified value will be a multiple of
8-bytes.
.SS Max RMA Ordered Size
.PP
The maximum ordered size specifies the delivery order of transport data
into target memory for RMA and atomic operations.
Data ordering is separate, but dependent on message ordering (defined
below).
Data ordering is unspecified where message order is not defined.
.PP
Data ordering refers to the access of target memory by subsequent
operations.
When back to back RMA read or write operations access the same
registered memory location, data ordering indicates whether the second
operation reads or writes the target memory after the first operation
has completed.
Because RMA ordering applies between two operations, and not within a
single data transfer, ordering is defined per byte-addressable memory
location.
I.e.
ordering specifies whether location X is accessed by the second
operation after the first operation.
Nothing is implied about the completion of the first operation before
the second operation is initiated.
.PP
In order to support large data transfers being broken into multiple
packets and sent using multiple paths through the fabric, data ordering
may be limited to transfers of a specific size or less.
Providers specify when data ordering is maintained through the following
values.
Note that even if data ordering is not maintained, message ordering may
be.
.PP
\f[I]max_order_raw_size\f[] : Read after write size.
If set, an RMA or atomic read operation issued after an RMA or atomic
write operation, both of which are smaller than the size, will be
ordered.
The RMA or atomic read operation will see the results of the previous
RMA or atomic write.
.PP
\f[I]max_order_war_size\f[] : Write after read size.
If set, an RMA or atomic write operation issued after an RMA or atomic
read operation, both of which are smaller than the size, will be
ordered.
The RMA or atomic read operation will see the initial value of the
target memory region before a subsequent RMA or atomic write updates the
value.
.PP
\f[I]max_order_waw_size\f[] : Write after write size.
If set, an RMA or atomic write operation issued after an RMA or atomic
write operation, both of which are smaller than the size, will be
ordered.
The target memory region will reflect the results of the second RMA or
atomic write.
.PP
An order size value of 0 indicates that ordering is not guaranteed.
A value of -1 guarantees ordering for any data size.
.SS mem_tag_format - Memory Tag Format
.PP
The memory tag format is a bit array used to convey the number of tagged
bits supported by a provider.
Additionally, it may be used to divide the bit array into separate
fields.
The mem_tag_format optionally begins with a series of bits set to 0, to
signify bits which are ignored by the provider.
Following the initial prefix of ignored bits, the array will consist of
alternating groups of bits set to all 1\[aq]s or all 0\[aq]s.
Each group of bits corresponds to a tagged field.
The implication of defining a tagged field is that when a mask is
applied to the tagged bit array, all bits belonging to a single field
will either be set to 1 or 0, collectively.
.PP
For example, a mem_tag_format of 0x30FF indicates support for 14 tagged
bits, separated into 3 fields.
The first field consists of 2-bits, the second field 4-bits, and the
final field 8-bits.
Valid masks for such a tagged field would be a bitwise OR\[aq]ing of
zero or more of the following values: 0x3000, 0x0F00, and 0x00FF.
.PP
By identifying fields within a tag, a provider may be able to optimize
their search routines.
An application which requests tag fields must provide tag masks that
either set all mask bits corresponding to a field to all 0 or all 1.
When negotiating tag fields, an application can request a specific
number of fields of a given size.
A provider must return a tag format that supports the requested number
of fields, with each field being at least the size requested, or fail
the request.
A provider may increase the size of the fields.
.PP
It is recommended that field sizes be ordered from smallest to largest.
A generic, unstructured tag and mask can be achieved by requesting a bit
array consisting of alternating 1\[aq]s and 0\[aq]s.
.SS msg_order - Message Ordering
.PP
Message ordering refers to the order in which transport layer headers
(as viewed by the application) are processed.
Relaxed message order enables data transfers to be sent and received out
of order, which may improve performance by utilizing multiple paths
through the fabric from the initiating endpoint to a target endpoint.
Message order applies only between a single source and destination
endpoint pair.
Ordering between different target endpoints is not defined.
.PP
Message order is determined using a set of ordering bits.
Each set bit indicates that ordering is maintained between data
transfers of the specified type.
Message order is defined for [read | write | send] operations submitted
by an application after [read | write | send] operations.
.PP
Message ordering only applies to the processing of transport headers.
Message ordering is necessary, but does not guarantee the order in which
data is sent or received by the transport layer.
.PP
\f[I]FI_ORDER_RAR\f[] : Read after read.
If set, RMA and atomic read operations are processed in the order
submitted relative to other RMA and atomic read operations.
If not set, RMA and atomic reads may be processed out of order from
their submission.
.PP
\f[I]FI_ORDER_RAW\f[] : Read after write.
If set, RMA and atomic read operations are processed in the order
submitted relative to RMA and atomic write operations.
If not set, RMA and atomic reads may be processed ahead of RMA and
atomic writes.
.PP
\f[I]FI_ORDER_RAS\f[] : Read after send.
If set, RMA and atomic read operations are processed in the order
submitted relative to message send operations, including tagged sends.
If not set, RMA and atomic reads may be processed ahead of sends.
.PP
\f[I]FI_ORDER_WAR\f[] : Write after read.
If set, RMA and atomic write operations are processed in the order
submitted relative to RMA and atomic read operations.
If not set, RMA and atomic writes may be processed ahead of RMA and
atomic reads.
.PP
\f[I]FI_ORDER_WAW\f[] : Write after write.
If set, RMA and atomic write operations are processed in the order
submitted relative to other RMA and atomic write operations.
If not set, RMA and atomic writes may be processed out of order from
their submission.
.PP
\f[I]FI_ORDER_WAS\f[] : Write after send.
If set, RMA and atomic write operations are processed in the order
submitted relative to message send operations, including tagged sends.
If not set, RMA and atomic writes may be processed ahead of sends.
.PP
\f[I]FI_ORDER_SAR\f[] : Send after read.
If set, message send operations, including tagged sends, are processed
in order submitted relative to RMA and atomic read operations.
If not set, message sends may be processed ahead of RMA and atomic
reads.
.PP
\f[I]FI_ORDER_SAW\f[] : Send after write.
If set, message send operations, including tagged sends, are processed
in order submitted relative to RMA and atomic write operations.
If not set, message sends may be processed ahead of RMA and atomic
writes.
.PP
\f[I]FI_ORDER_SAS\f[] : Send after send.
If set, message send operations, including tagged sends, are processed
in the order submitted relative to other message send.
If not set, message sends may be processed out of order from their
submission.
.SS comp_order - Completion Ordering
.PP
Completion ordering refers to the order in which completed requests are
written into the completion queue.
Completion ordering is similar to message order.
Relaxed completion order may enable faster reporting of completed
transfers, allow acknowledgments to be sent over different fabric paths,
and support more sophisticated retry mechanisms.
This can result in lower-latency completions, particularly when using
unconnected endpoints.
Strict completion ordering may require that providers queue completed
operations or limit available optimizations
.PP
For transmit requests, completion ordering depends on the endpoint
communication type.
For unreliable communication, completion ordering applies to all data
transfer requests submitted to an endpoint.
For reliable communication, completion ordering only applies to requests
that target a single destination endpoint.
Completion ordering of requests that target different endpoints over a
reliable transport is not defined.
.PP
Applications should specify the completion ordering that they support or
require.
Providers should return the completion order that they actually provide,
with the constraint that the returned ordering is stricter than that
specified by the application.
Supported completion order values are:
.PP
\f[I]FI_ORDER_NONE\f[] : No ordering is defined for completed
operations.
Requests submitted to the transmit and receive queues may complete in
any order.
.PP
\f[I]FI_ORDER_STRICT\f[] : Requests complete in the order in which they
are submitted, in the case of transmit requests, or processed, in the
case of receive operations, by the provider.
Transmit operations complete in the order in which the requests were
submitted.
Receive operations complete in order, subject to buffer matching.
.SS tx_ctx_cnt - Transmit Context Count
.PP
Number of transmit contexts to associate with the endpoint.
If not specified (0), 1 context will be assigned if the endpoint
supports outbound transfers.
Transmit contexts are independent transmit queues that may be separately
configured.
Each transmit context may be bound to a separate CQ, and no ordering is
defined between contexts.
Additionally, no synchronization is needed when accessing contexts in
parallel.
.PP
If the count is set to the value FI_SHARED_CONTEXT, the endpoint will be
configured to use a shared transmit context, if supported by the
provider.
Providers that do not support shared transmit contexts will fail the
request.
.PP
See the scalable endpoint and shared contexts sections for additional
details.
.SS rx_ctx_cnt - Receive Context Count
.PP
Number of receive contexts to associate with the endpoint.
If not specified, 1 context will be assigned if the endpoint supports
inbound transfers.
Receive contexts are independent processing queues that may be
separately configured.
Each receive context may be bound to a separate CQ, and no ordering is
defined between contexts.
Additionally, no synchronization is needed when accessing contexts in
parallel.
.PP
If the count is set to the value FI_SHARED_CONTEXT, the endpoint will be
configured to use a shared receive context, if supported by the
provider.
Providers that do not support shared receive contexts will fail the
request.
.PP
See the scalable endpoint and shared contexts sections for additional
details.
.SH SCALABLE ENDPOINTS
.PP
A scalable endpoint is a communication portal that supports multiple
transmit and receive contexts.
Scalable endpoints are loosely modeled after the networking concept of
transmit/receive side scaling, also known as multi-queue.
Support for scalable endpoints is domain specific.
Scalable endpoints may improve the performance of multi-threaded and
parallel applications, by allowing threads to access independent
transmit and receive queues.
A scalable endpoint has a single transport level address, which can
reduce the memory requirements needed to store remote addressing data,
versus using standard endpoints.
Scalable endpoints cannot be used directly for communication operations,
and require the application to explicitly create transmit and receive
contexts as described below.
.SS fi_tx_context
.PP
Transmit contexts are independent transmit queues.
Ordering and synchronization between contexts are not defined.
Conceptually a transmit context behaves similar to a send-only endpoint.
A transmit context may be configured with relaxed capabilities, and has
its own completion queue.
The number of transmit contexts associated with an endpoint is specified
during endpoint creation.
.PP
The fi_tx_context call is used to retrieve a specific context,
identified by an index.
Providers may dynamically allocate contexts when fi_tx_context is
called, or may statically create all contexts when fi_endpoint is
invoked.
By default, a transmit context inherits the properties of its associated
endpoint.
However, applications may request context specific attributes through
the attr parameter.
Support for per transmit context attributes is provider specific and not
guaranteed.
Providers will return the actual attributes assigned to the context
through the attr parameter, if provided.
.IP
.nf
\f[C]
struct\ fi_tx_attr\ {
\ \ \ \ uint64_t\ \ caps;
\ \ \ \ uint64_t\ \ mode;
\ \ \ \ uint64_t\ \ op_flags;
\ \ \ \ uint64_t\ \ msg_order;
\ \ \ \ uint64_t\ \ comp_order;
\ \ \ \ size_t\ \ \ \ inject_size;
\ \ \ \ size_t\ \ \ \ size;
\ \ \ \ size_t\ \ \ \ iov_limit;
\ \ \ \ size_t\ \ \ \ rma_iov_limit;
};
\f[]
.fi
.PP
\f[I]caps\f[] : The requested capabilities of the context.
The capabilities must be a subset of those requested of the associated
endpoint.
See the CAPABILITIES section if fi_getinfo(3) for capability details.
.PP
\f[I]mode\f[] : The operational mode bits of the context.
The mode bits will be a subset of those associated with the endpoint.
See the MODE section of fi_getinfo(3) for details.
.PP
\f[I]op_flags\f[] : Flags that control the operation of operations
submitted against the context.
Applicable flags are listed in the Operation Flags section.
.PP
\f[I]msg_order\f[] : The message ordering requirements of the context.
The message ordering must be the same or more relaxed than those
specified of the associated endpoint.
See the fi_endpoint Message Ordering section.
.PP
\f[I]comp_order\f[] : The completion ordering requirements of the
context.
The completion ordering must be the same or more relaxed than those
specified of the associated endpoint.
See the fi_endpoint Completion Ordering section.
.PP
\f[I]inject_size\f[] : The requested inject operation size (see the
FI_INJECT flag) that the context will support.
See the fi_endpoint Inject Size section.
.PP
\f[I]size\f[] : The size of the context, in bytes.
The size is usually used as an output value by applications wishing to
track if sufficient space is available in the local queue to post a new
operation.
.PP
\f[I]iov_limit\f[] : This is the maximum number of IO vectors
(scatter-gather elements) that a single posted operation may reference.
.PP
\f[I]rma_iov_limit\f[] : This is the maximum number of RMA IO vectors
(scatter-gather elements) that an RMA or atomic operation may reference.
The rma_iov_limit corresponds to the rma_iov_count values in RMA and
atomic operations.
See struct fi_msg_rma and struct fi_msg_atomic in fi_rma.3 and
fi_atomic.3, for additional details.
This limit applies to both the number of RMA IO vectors that may be
specified when initiating an operation from the local endpoint, as well
as the maximum number of IO vectors that may be carried in a single
request from a remote endpoint.
.SS fi_rx_context
.PP
Receive contexts are independent receive queues for receiving incoming
data.
Ordering and synchronization between contexts are not guaranteed.
Conceptually a receive context behaves similar to a receive-only
endpoint.
A receive context may be configured with relaxed endpoint capabilities,
and has its own completion queue.
The number of receive contexts associated with an endpoint is specified
during endpoint creation.
.PP
Receive contexts are often associated with steering flows, that specify
which incoming packets targeting a scalable endpoint to process.
However, receive contexts may be targeted directly by the initiator, if
supported by the underlying protocol.
Such contexts are referred to as \[aq]named\[aq].
Support for named contexts must be indicated by setting the caps
FI_NAMED_RX_CTX capability when the corresponding endpoint is created.
Support for named receive contexts is coordinated with address vectors.
See fi_av(3) and fi_rx_addr(3).
.PP
The fi_rx_context call is used to retrieve a specific context,
identified by an index.
Providers may dynamically allocate contexts when fi_rx_context is
called, or may statically create all contexts when fi_endpoint is
invoked.
By default, a receive context inherits the properties of its associated
endpoint.
However, applications may request context specific attributes through
the attr parameter.
Support for per receive context attributes is provider specific and not
guaranteed.
Providers will return the actual attributes assigned to the context
through the attr parameter, if provided.
.IP
.nf
\f[C]
struct\ fi_rx_attr\ {
\ \ \ \ uint64_t\ \ caps;
\ \ \ \ uint64_t\ \ mode;
\ \ \ \ uint64_t\ \ op_flags;
\ \ \ \ uint64_t\ \ msg_order;
\ \ \ \ uint64_t\ \ comp_order;
\ \ \ \ size_t\ \ \ \ total_buffered_recv;
\ \ \ \ size_t\ \ \ \ size;
\ \ \ \ size_t\ \ \ \ iov_limit;
};
\f[]
.fi
.PP
\f[I]caps\f[] : The requested capabilities of the context.
The capabilities must be a subset of those requested of the associated
endpoint.
See the CAPABILITIES section if fi_getinfo(3) for capability details.
.PP
\f[I]mode\f[] : The operational mode bits of the context.
The mode bits will be a subset of those associated with the endpoint.
See the MODE section of fi_getinfo(3) for details.
.PP
\f[I]op_flags\f[] : Flags that control the operation of operations
submitted against the context.
Applicable flags are listed in the Operation Flags section.
.PP
\f[I]msg_order\f[] : The message ordering requirements of the context.
The message ordering must be the same or more relaxed than those
specified of the associated endpoint.
See the fi_endpoint Message Ordering section.
.PP
\f[I]comp_order\f[] : The completion ordering requirements of the
context.
The completion ordering must be the same or more relaxed than those
specified of the associated endpoint.
See the fi_endpoint Completion Ordering section.
.PP
\f[I]total_buffered_recv\f[] : Defines the total available space
allocated by the provider to buffer messages that are received for which
there is no matching receive operation.
If set to 0, any messages that arrive before a receive buffer has been
posted are lost.
.PP
\f[I]size\f[] : The size of the context, in bytes.
The size is usually used as an output value by applications wishing to
track if sufficient space is available in the local queue to post a new
operation.
.PP
\f[I]iov_limit\f[] : This is the maximum number of IO vectors
(scatter-gather elements) that a single posted operating may reference.
.SH SHARED CONTEXTS
.PP
Shared contexts are transmit and receive contexts explicitly shared
among one or more endpoints.
A sharable context allows an application to use a single dedicated
provider resource among multiple transport addressable endpoints.
This can greatly reduce the resources needed to manage communication
over multiple endpoints by multiplexing transmit and/or receive
processing, with the potential cost of serializing access across
multiple endpoints.
Support for sharable contexts is domain specific.
.PP
Conceptually, sharable transmit contexts are transmit queues that may be
accessed by many endpoints.
The use of a shared transmit context is mostly opaque to an application.
Applications must allocate and bind shared transmit contexts to
endpoints, but operations are posted directly to the endpoint.
Shared transmit contexts are not associated with completion queues or
counters.
Completed operations are posted to the CQs bound to the endpoint.
An endpoint may only be associated with a single shared transmit
context.
.PP
Unlike shared transmit contexts, applications interact directly with
shared receive contexts.
Users post receive buffers directly to a shared receive context, with
the buffers usable by any endpoint bound to the shared receive context.
Shared receive contexts are not associated with completion queues or
counters.
Completed receive operations are posted to the CQs bound to the
endpoint.
An endpoint may only be associated with a single receive context, and
all connectless endpoints associated with a shared receive context must
also share the same address vector.
.PP
Endpoints associated with a shared transmit context may use dedicated
receive contexts, and vice-versa.
Or an endpoint may use shared transmit and receive contexts.
And there is no requirement that the same group of endpoints sharing a
context of one type also share the context of an alternate type.
Furthermore, an endpoint may use a shared context of one type, but a
scalable set of contexts of the alternate type.
.SS fi_stx_context
.PP
This call is used to open a sharable transmit context.
See fi_tx_context call under the SCALABLE ENDPOINTS section for details
on the transit context attributes.
The exception is that endpoints attached to a shared transmit context
must use a subset of the transmit context attributes.
This is opposite of the requirement for scalable endpoints.
.SS fi_srx_context
.PP
This allocates a sharable receive context.
See fi_rx_context call under SCALABLE ENDPOINTS section for details on
the receive context attributes.
The exception is that endpoints attached to a shared receive context
must use a subset of the receive context attributes.
This is opposite of the requirement for scalable endpoints.
.SH OPERATION FLAGS
.PP
Operation flags are obtained by OR-ing the following flags together.
Operation flags define the default flags applied to an endpoint\[aq]s
data transfer operations, where a flags parameter is not available.
Data transfer operations that take flags as input override the op_flags
value of an endpoint.
.PP
\f[I]FI_INJECT\f[] : Indicates that all outbound data buffers should be
returned to the user\[aq]s control immediately after a data transfer
call returns, even if the operation is handled asynchronously.
This may require that the provider copy the data into a local buffer and
transfer out of that buffer.
A provider may limit the total amount of send data that may be buffered
and/or the size of a single send.
.PP
\f[I]FI_MULTI_RECV\f[] : Applies to posted receive operations.
This flag allows the user to post a single buffer that will receive
multiple incoming messages.
Received messages will be packed into the receive buffer until the
buffer has been consumed.
Use of this flag may cause a single posted receive operation to generate
multiple completions as messages are placed into the buffer.
The placement of received data into the buffer may be subjected to
provider specific alignment restrictions.
The buffer will be returned to the application\[aq]s control, and an
\f[I]FI_MULTI_RECV\f[] completion will be generated, when a message is
received that cannot fit into the remaining free buffer space.
.PP
\f[I]FI_COMPLETION\f[] : Indicates that a completion entry should be
generated for data transfer operations.
.PP
\f[I]FI_REMOTE_SIGNAL\f[] : Indicates that a completion entry at the
target process should be generated for the given operation.
The remote endpoint must be configured with FI_REMOTE_SIGNAL, or this
flag will be ignored by the target.
The local endpoint must be configured with the FI_REMOTE_SIGNAL
capability in order to specify this flag.
.PP
\f[I]FI_REMOTE_COMPLETE\f[] : Indicates that local completions should
not be generated until the operation has completed on the remote side.
When set, if the target endpoint experiences an error receiving the
transferred data, that error will be reported back to the initiator of
the request.
This includes errors which may not normally be reported to the
initiator.
For example, if the receive data is truncated at the target because the
provided receive buffer is too small, the initiator will be notified of
the truncation.
.SH NOTES
.PP
Users should call fi_close to release all resources allocated to the
fabric endpoint.
.PP
Endpoints allocated with the FI_CONTEXT mode set must typically provide
struct fi_context as their per operation context parameter.
(See fi_getinfo.3 for details.)
 However, when FI_COMPLETION is enabled to suppress completion entries,
and an operation is initiated without FI_COMPLETION flag set, then the
context parameter is ignored.
An application does not need to pass in a valid struct fi_context into
such data transfers.
.PP
Operations that complete in error that are not associated with valid
operational context will use the endpoint context in any error reporting
structures.
.PP
Users can attach both counters and completion queues to an endpoint.
When both counter and completion queue are attached, a successful
completion increments the counter and does not generate a completion
entry in the completion queue.
Operations that complete with an error increment the error counter and
generate a completion event.
.SH RETURN VALUES
.PP
Returns 0 on success.
On error, a negative value corresponding to fabric errno is returned.
.PP
Fabric errno values are defined in \f[C]rdma/fi_errno.h\f[].
.SH ERRORS
.PP
\f[I]-FI_EDOMAIN\f[] : A resource domain was not bound to the endpoint
or an attempt was made to bind multiple domains.
.PP
\f[I]-FI_ENOCQ\f[] : The endpoint has not been configured with necessary
event queue.
.PP
\f[I]-FI_EOPBADSTATE\f[] : The endpoint\[aq]s state does not permit the
requested operation.
.SH SEE ALSO
.PP
\f[C]fi_getinfo\f[](3), \f[C]fi_domain\f[](3), \f[C]fi_msg\f[](3),
\f[C]fi_tagged\f[](3), \f[C]fi_rma\f[](3)
.SH AUTHORS
OpenFabrics.
