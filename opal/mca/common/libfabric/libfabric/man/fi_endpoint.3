.TH fi_endpoint 3 "2014\-11\-24" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
.SH NAME
.PP
fi_endpoint - Fabric endpoint operations
.TP
.B fi_endpoint / fi_pendpoint / fi_close
Allocate or close an endpoint.
.RS
.RE
.TP
.B fi_ep_bind
Associate an endpoint with an event queue, completion queue, address
vector, or memory region
.RS
.RE
.TP
.B fi_scalable_ep_bind
Associate a scalable endpoint with an address vector
.RS
.RE
.TP
.B fi_enable
Transitions an endpoint into an active state.
.RS
.RE
.TP
.B fi_cancel
Cancel a pending asynchronous data transfer
.RS
.RE
.TP
.B fi_alias
Create an alias to the endpoint
.RS
.RE
.TP
.B fi_control
Control endpoint operation.
.RS
.RE
.TP
.B fi_getopt / fi_setopt
Get or set endpoint options.
.RS
.RE
.TP
.B fi_rx_context / fi_tx_context / fi_srx_context / fi_stx_context
Open a transmit or receive context.
.RS
.RE
.SH SYNOPSIS
.IP
.nf
\f[C]
#include\ <rdma/fabric.h>

#include\ <rdma/fi_endpoint.h>

int\ fi_endpoint(struct\ fid_domain\ *domain,\ struct\ fi_info\ *info,
\ \ \ \ struct\ fid_ep\ **ep,\ void\ *context);

int\ fi_scalable_ep(struct\ fid_domain\ *domain,\ struct\ fi_info\ *info,
\ \ \ \ struct\ fid_sep\ **ep,\ void\ *context);

int\ fi_pendpoint(struct\ fi_fabric\ *fabric,\ struct\ fi_info\ *info,
\ \ \ \ struct\ fid_pep\ **pep,\ void\ *context);

int\ fi_tx_context(struct\ fid_ep\ *ep,\ int\ index,
\ \ \ \ struct\ fi_tx_ctx_attr\ *attr,\ struct\ fid_ep\ **tx_ep,
\ \ \ \ void\ *context);

int\ fi_rx_context(struct\ fid_ep\ *ep,\ int\ index,
\ \ \ \ struct\ fi_rx_ctx_attr\ *attr,\ struct\ fid_ep\ **rx_ep,
\ \ \ \ void\ *context);

int\ fi_stx_context(struct\ fid_domain\ *domain,
\ \ \ \ struct\ fi_tx_ctx_attr\ *attr,\ struct\ fid_stx\ **stx,
\ \ \ \ void\ *context);

int\ fi_srx_context(struct\ fid_domain\ *domain,
\ \ \ \ struct\ fi_rx_ctx_attr\ *attr,\ struct\ fid_ep\ **rx_ep,
\ \ \ \ void\ *context);

int\ fi_close(struct\ fid\ *ep);

int\ fi_ep_bind(struct\ fid_ep\ *ep,\ struct\ fid\ *fid,\ uint64_t\ flags);

int\ fi_scalable_ep_bind(struct\ fid_sep\ *sep,\ struct\ fid\ *fid,\ uint64_t\ flags);

int\ fi_enable(struct\ fid_ep\ *ep);

int\ fi_cancel(struct\ fid_ep\ *ep,\ void\ *context);

int\ fi_alias(struct\ fid_ep\ *ep,\ fid_t\ *alias_ep,\ uint64_t\ flags);

int\ fi_control(struct\ fid\ *ep,\ int\ command,\ void\ *arg);

int\ fi_getopt(struct\ fid_\ *ep,\ int\ level,\ int\ optname,
\ \ \ \ void\ *optval,\ size_t\ *optlen);

int\ fi_setopt(struct\ fid\ *ep,\ int\ level,\ int\ optname,
\ \ \ \ const\ void\ *optval,\ size_t\ optlen);
\f[]
.fi
.SH ARGUMENTS
.PP
\f[I]fid\f[] : On creation, specifies a fabric or access domain.
On bind, identifies the event queue, completion queue or address vector
to bind to the endpoint.
.PP
\f[I]info\f[] : Details about the fabric interface endpoint to be
opened, obtained from fi_getinfo.
.PP
\f[I]ep\f[] : A fabric endpoint.
.PP
\f[I]sep\f[] : A scalable fabric endpoint.
.PP
\f[I]fid\f[] : Fabric identifier of an associated resource.
.PP
\f[I]context\f[] : Context associated with the endpoint or asynchronous
operation.
.PP
\f[I]flags\f[] : Additional flags to apply to the operation.
.PP
\f[I]command\f[] : Command of control operation to perform on endpoint.
.PP
\f[I]arg\f[] : Optional control argument
.PP
\f[I]level\f[] : Protocol level at which the desired option resides.
.PP
\f[I]optname\f[] : The protocol option to read or set.
.PP
\f[I]optval\f[] : The option value that was read or to set.
.PP
\f[I]optlen\f[] : The size of the optval buffer.
.SH DESCRIPTION
.PP
Endpoints are transport level communication portals.
There are two types of endpoints: active and passive.
Passive endpoints belong to a fabric domain and are used to listen for
incoming connection requests.
Active endpoints belong to access domains and can perform data
transfers.
.PP
Data transfer interfaces are bound to active endpoints.
Active endpoints may be connection-oriented or connectionless, and may
provide data reliability.
.PP
Active endpoints are created in the disabled state.
They must transition into an enabled state before accepting data
transfer operations, including posting of receive buffers.
The fi_enable call is used to transition an endpoint into an active
enabled state.
The fi_connect and fi_accept calls will also transition an endpoint into
the enabled state, if it is not already active.
.PP
In order to transition an endpoint into an enabled state, it must be
bound to one or more fabric resources.
An endpoint that will generate asynchronous completions, either through
data transfer operations or communication establishment events, must be
bound to the appropriate completion queues or event queues before being
enabled.
.PP
Once an endpoint has been activated, it may be associated with memory
regions and address vectors.
Receive buffers may be posted to it, and calls may be made to connection
establishment routines.
Connectionless endpoints may also perform data transfers.
.PP
The behavior of an endpoint may be adjusted by setting its control data
and protocol options.
This allows the underlying provider to redirect function calls to
implementations optimized to meet the desired application behavior.
.SS fi_endpoint / fi_pendpoint / fi_scalable_ep
.PP
fi_endpoint allocates a new active endpoint.
fi_pendpoint allocates a new passive endpoint.
fi_scalable_ep allocates a scalable endpoint.
The properties and behavior of the endpoint are defined based on the
provided struct fi_info.
See fi_getinfo for additional details on fi_info.
fi_info flags that control the operation of an endpoint are defined
below.
See section SCALABLE ENDPOINTS.
.PP
If an active endpoint is associated with a connection request, the
fi_info connreq must reference the corresponding request.
.SS fi_close
.PP
Closes an endpoint and release all resources associated with it.
.SS fi_ep_bind
.PP
fi_ep_bind is used to associate an endpoint with hardware resources.
The common use of fi_ep_bind is to direct asynchronous operations
associated with an endpoint to a completion queue.
An endpoint must be bound with CQs capable of reporting completions for
any asynchronous operation initiated on the endpoint.
This is true even for endpoints which are configured to suppress
successful completions, in order that operations that complete in error
may be reported to the user.
For passive endpoints, this requires binding the endpoint with an EQ
that supports the communication management (CM) domain.
.PP
An active endpoint may direct asynchronous completions to different CQs,
based on the type of operation.
This is specified using fi_ep_bind flags.
The following flags may be used separately or OR\[aq]ed together when
binding an endpoint to a completion domain CQ.
.PP
\f[I]FI_SEND\f[] : Directs the completion of outbound data transfer
requests to the specified completion queue.
This includes send message, RMA, and atomic operations.
.PP
\f[I]FI_RECV\f[] : Directs the notification of inbound data transfers to
the specified completion queue.
This includes received messages.
.PP
\f[I]FI_COMPLETION\f[] : If FI_COMPLETION is specified, the indicated
data transfer operations won\[aq]t generate entries for successful
completions in the completion queue unless FI_COMPLETION is set for that
specific operation.
FI_COMPLETION must be OR\[aq]ed with FI_SEND and/or FI_RECV flags.
.PP
When set the user must determine when a request that does NOT have
FI_COMPLETION set has completed indirectly, usually based on the
completion of a subsequent operation.
Use of this flag may improve performance by allowing the provider to
avoid writing a completion entry for every operation.
.PP
The use of FI_COMPLETION is often paired with the call fi_sync.
FI_COMPLETION allows the user to suppress completions from being
generated.
In order for the application to ensure that all previous operations have
completed, the application may call fi_sync.
The successful completion of fi_sync indicates that all prior operations
have completed successfully.
.PP
An endpoint may also, or instead, be bound to a fabric counter.
When binding an endpoint to a counter, the following flags may be
specified.
.PP
\f[I]FI_SEND\f[] : Increments the specified counter whenever a
successful message is transferred over the endpoint.
Sent messages include both tagged and normal message operations.
.PP
\f[I]FI_RECV\f[] : Increments the specified counter whenever a
successful message is received over the endpoint.
Received messages include both tagged and normal message operations.
.PP
\f[I]FI_READ\f[] : Increments the specified counter whenever a
successful RMA read or atomic fetch operation is initiated from the
endpoint.
.PP
\f[I]FI_WRITE\f[] : Increments the specified counter whenever a
successful RMA write or atomic operation is initiated from the endpoint.
.PP
\f[I]FI_REMOTE_READ\f[] : Increments the specified counter whenever a
successful RMA read or atomic fetch operation is initiated from a remote
endpoint that targets the given endpoint.
.PP
\f[I]FI_REMOTE_WRITE\f[] : Increments the specified counter whenever a
successful RMA write or atomic operation is initiated from a remote
endpoint that targets the given endpoint.
.PP
Connectionless endpoints must be bound to a single address vector.
.SS fi_scalable_ep_bind
.PP
fi_scalable_ep_bind is used to associate a scalable endpoint with an
address vector.
See section on SCALABLE ENDPOINTS.
A scalable endpoint has a single transport level address and can support
multiple transmit and receive contexts.
The transmit and receive contexts share the transport-level address.
Address vectors that are bound to scalable endpoints are implicitly
bound to any transmit or receive contexts created using the scalable
endpoint.
.SS fi_enable
.PP
This call transitions the endpoint into an enabled state.
An endpoint must be enabled before it may be used to perform data
transfers.
Enabling an endpoint typically results in hardware resources being
assigned to it.
.PP
Calling connect or accept on an endpoint will implicitly enable an
endpoint if it has not already been enabled.
.SS fi_cancel
.PP
fi_cancel attempts to cancel an outstanding asynchronous operation.
The endpoint must have been configured to support cancelable operations
-- see FI_CANCEL flag -- in order for this call to succeed.
Canceling an operation causes the fabric provider to search for the
operation and, if it is still pending, complete it as having been
canceled.
The cancel operation will complete within a bounded period of time.
.SS fi_alias
.PP
This call creates an alias to the specified endpoint.
Conceptually, an endpoint alias provides an alternate software path from
the application to the underlying provider hardware.
Applications configure an alias endpoint with data transfer flags,
specified through the fi_alias call.
Typically, the data transfer flags will be different than those assigned
to the actual endpoint.
The alias mechanism allows a single endpoint to have multiple optimized
software interfaces.
All allocated aliases must be closed for the underlying endpoint to be
released.
.SS fi_control
.PP
The control operation is used to adjust the default behavior of an
endpoint.
It allows the underlying provider to redirect function calls to
implementations optimized to meet the desired application behavior.
As a result, calls to fi_ep_control must be serialized against all other
calls to an endpoint.
.PP
The base operation of an endpoint is selected during creation using
struct fi_info.
The following control commands and arguments may be assigned to an
endpoint.
.PP
**FI_GETOPSFLAG -- uint64_t \f[I]flags\f[]* : Used to retrieve the
current value of flags associated with data transfer operations
initiated on the endpoint.
See below for a list of control flags.
.PP
**FI_SETOPSFLAG -- uint64_t \f[I]flags\f[]* : Used to change the data
transfer operation flags associated with an endpoint.
The FI_READ, FI_WRITE, FI_SEND, FI_RECV flags indicate the type of data
transfer that the flags should apply to, with other flags OR\[aq]ed in.
Valid control flags are defined below.
.SS fi_getopt / fi_setopt
.PP
Endpoint protocol operations may be retrieved using fi_getopt or set
using fi_setopt.
Applications specify the level that a desired option exists, identify
the option, and provide input/output buffers to get or set the option.
fi_setopt provides an application a way to adjust low-level protocol and
implementation specific details of an endpoint.
.PP
The following option levels and option names and parameters are defined.
.PP
\f[I]FI_OPT_ENDPOINT\f[]
.IP \[bu] 2
\f[I]FI_OPT_MIN_MULTI_RECV - size_t\f[] : Defines the minimum receive
buffer space available when the receive buffer is automatically freed
(see FI_MULTI_RECV).
.SH ENDPOINT ATTRIBUTES
.PP
The fi_ep_attr structure defines the set of attributes associated with
an endpoint.
.IP
.nf
\f[C]
struct\ fi_ep_attr\ {
\ \ \ \ uint64_t\ \ protocol;
\ \ \ \ size_t\ \ \ \ max_msg_size;
\ \ \ \ size_t\ \ \ \ inject_size;
\ \ \ \ size_t\ \ \ \ total_buffered_recv;
\ \ \ \ size_t\ \ \ \ msg_prefix_size;
\ \ \ \ size_t\ \ \ \ max_order_raw_size;
\ \ \ \ size_t\ \ \ \ max_order_war_size;
\ \ \ \ size_t\ \ \ \ max_order_waw_size;
\ \ \ \ uint64_t\ \ mem_tag_format;
\ \ \ \ uint64_t\ \ msg_order;
\ \ \ \ size_t\ \ \ \ tx_ctx_cnt;
\ \ \ \ size_t\ \ \ \ rx_ctx_cnt;
};
\f[]
.fi
.SS Protocol
.PP
Specifies the low-level end to end protocol employed by the provider.
A matching protocol must be used by communicating endpoints to ensure
interoperability.
The following protocol values are defined.
Provider specific protocols are also allowed.
Provider specific protocols will be indicated by having the upper 3
bytes of the protocol value set to the vendor OUI.
.PP
\f[I]FI_PROTO_UNSPEC\f[] : The protocol is not specified.
This is usually provided as input, with other attributes of the socket
or the provider selecting the actual protocol.
.PP
\f[I]FI_PROTO_RDMA_CM_IB_RC\f[] : The protocol runs over Infiniband
reliable-connected queue pairs, using the RDMA CM protocol for
connection establishment.
.PP
\f[I]FI_PROTO_IWARP\f[] : The protocol runs over the Internet wide area
RDMA protocol transport.
.PP
\f[I]FI_PROTO_IB_UD\f[] : The protocol runs over Infiniband unreliable
datagram queue pairs.
.PP
\f[I]FI_PROTO_PSMX\f[] : The protocol is based on an Intel proprietary
protocol known as PSM, performance scaled messaging.
PSMX is an extended version of the PSM protocol to support the libfabric
interfaces.
.SS max_msg_size - Max Message Size
.PP
Defines the maximum size for an application data transfer as a single
operation.
.SS inject_size - Inject Size
.PP
Defines the default inject operation size (see the FI_INJECT flag) that
an endpoint will support.
This value applies per send operation.
.SS total_buffered_recv - Total Buffered Receive
.PP
Defines the total available space allocated by the provider to buffer
received messages (see the FI_BUFFERED_RECV flag).
.SS msg_prefix_size - Message Prefix Size
.PP
Specifies the size of any required message prefix buffer space.
This field will be 0 unless the FI_MSG_PREFIX mode is enabled.
If msg_prefix_size is > 0 the specified value will be a multiple of
8-bytes.
.SS Max RMA Ordered Size
.PP
The maximum ordered size specifies the delivery order of transport data
into target memory for RMA and atomic operations.
Data ordering is separate, but dependent on message ordering (defined
below).
Data ordering is unspecified where message order is not defined.
.PP
Data ordering refers to the access of target memory by subsequent
operations.
When back to back RMA read or write operations access the same
registered memory location, data ordering indicates whether the second
operation reads or writes the target memory after the first operation
has completed.
Because RMA ordering applies between two operations, and not within a
single data transfer, ordering is defined per byte-addressable memory
location.
I.e.
ordering specifies whether location X is accessed by the second
operation after the first operation.
Nothing is implied about the completion of the first operation before
the second operation is initiated.
.PP
In order to support large data transfers being broken into multiple
packets and sent using multiple paths through the fabric, data ordering
may be limited to transfers of a specific size or less.
Providers specify when data ordering is maintained through the following
values.
Note that even if data ordering is not maintained, message ordering may
be.
.PP
\f[I]max_order_raw_size\f[] : Read after write size.
If set, an RMA or atomic read operation issued after an RMA or atomic
write operation, both of which are smaller than the size, will be
ordered.
The RMA or atomic read operation will see the results of the previous
RMA or atomic write.
.PP
\f[I]max_order_war_size\f[] : Write after read size.
If set, an RMA or atomic write operation issued after an RMA or atomic
read operation, both of which are smaller than the size, will be
ordered.
The RMA or atomic read operation will see the initial value of the
target memory region before a subsequent RMA or atomic write updates the
value.
.PP
\f[I]max_order_waw_size\f[] : Write after write size.
If set, an RMA or atomic write operation issued after an RMA or atomic
write operation, both of which are smaller than the size, will be
ordered.
The target memory region will reflect the results of the second RMA or
atomic write.
.PP
An order size value of 0 indicates that ordering is not guaranteed.
A value of -1 guarantees ordering for any data size.
.SS mem_tag_format - Memory Tag Format
.PP
The memory tag format is a bit array used to convey the number of tagged
bits supported by a provider.
Additionally, it may be used to divide the bit array into separate
fields.
The mem_tag_format optionally begins with a series of bits set to 0, to
signify bits which are ignored by the provider.
Following the initial prefix of ignored bits, the array will consist of
alternating groups of bits set to all 1\[aq]s or all 0\[aq]s.
Each group of bits corresponds to a tagged field.
The implication of defining a tagged field is that when a mask is
applied to the tagged bit array, all bits belonging to a single field
will either be set to 1 or 0, collectively.
.PP
For example, a mem_tag_format of 0x30FF indicates support for 14 tagged
bits, separated into 3 fields.
The first field consists of 2-bits, the second field 4-bits, and the
final field 8-bits.
Valid masks for such a tagged field would be a bitwise OR\[aq]ing of
zero or more of the following values: 0x3000, 0x0F00, and 0x00FF.
.PP
By identifying fields within a tag, a provider may be able to optimize
their search routines.
An application which requests tag fields must provide tag masks that
either set all mask bits corresponding to a field to all 0 or all 1.
When negotiating tag fields, an application can request a specific
number of fields of a given size.
A provider must return a tag format that supports the requested number
of fields, with each field being at least the size requested, or fail
the request.
A provider may increase the size of the fields.
.PP
It is recommended that field sizes be ordered from smallest to largest.
A generic, unstructured tag and mask can be achieved by requesting a bit
array consisting of alternating 1\[aq]s and 0\[aq]s.
.SS msg_order - Message Ordering
.PP
Message ordering refers to the order in which transport layer headers
(as viewed by the application) are processed.
Relaxed message order enables data transfers to be sent and received out
of order, which may improve performance by utilizing multiple paths
through the fabric from the initiating endpoint to a target endpoint.
Message order applies only between a single source and destination
endpoint pair.
Ordering between different target endpoints is not defined.
.PP
Message order is determined using a set of ordering bits.
Each set bit indicates that ordering is maintained between data
transfers of the specified type.
Message order is defined for [read | write | send] operations submitted
by an application after [read | write | send] operations.
.PP
Message ordering only applies to the processing of transport headers.
Message ordering is necessary, but does not guarantee the order in which
data is sent or received by the transport layer.
.PP
\f[I]FI_ORDER_RAR\f[] : Read after read.
If set, RMA and atomic read operations are processed in the order
submitted relative to other RMA and atomic read operations.
If not set, RMA and atomic reads may be processed out of order from
their submission.
.PP
\f[I]FI_ORDER_RAW\f[] : Read after write.
If set, RMA and atomic read operations are processed in the order
submitted relative to RMA and atomic write operations.
If not set, RMA and atomic reads may be processed ahead of RMA and
atomic writes.
.PP
\f[I]FI_ORDER_RAS\f[] : Read after send.
If set, RMA and atomic read operations are processed in the order
submitted relative to message send operations, including tagged sends.
If not set, RMA and atomic reads may be processed ahead of sends.
.PP
\f[I]FI_ORDER_WAR\f[] : Write after read.
If set, RMA and atomic write operations are processed in the order
submitted relative to RMA and atomic read operations.
If not set, RMA and atomic writes may be processed ahead of RMA and
atomic reads.
.PP
\f[I]FI_ORDER_WAW\f[] : Write after write.
If set, RMA and atomic write operations are processed in the order
submitted relative to other RMA and atomic write operations.
If not set, RMA and atomic writes may be processed out of order from
their submission.
.PP
\f[I]FI_ORDER_WAS\f[] : Write after send.
If set, RMA and atomic write operations are processed in the order
submitted relative to message send operations, including tagged sends.
If not set, RMA and atomic writes may be processed ahead of sends.
.PP
\f[I]FI_ORDER_SAR\f[] : Send after read.
If set, message send operations, including tagged sends, are processed
in order submitted relative to RMA and atomic read operations.
If not set, message sends may be processed ahead of RMA and atomic
reads.
.PP
\f[I]FI_ORDER_SAW\f[] : Send after write.
If set, message send operations, including tagged sends, are processed
in order submitted relative to RMA and atomic write operations.
If not set, message sends may be processed ahead of RMA and atomic
writes.
.PP
\f[I]FI_ORDER_SAS\f[] : Send after send.
If set, message send operations, including tagged sends, are processed
in the order submitted relative to other message send.
If not set, message sends may be processed out of order from their
submission.
.SS tx_ctx_cnt - Transmit Context Count
.PP
Number of transmit contexts to associate with the endpoint.
If not specified (0), 1 context will be assigned if the endpoint
supports outbound transfers.
Transmit contexts are independent command queues that may be separately
configured.
Each transmit context may be bound to a separate CQ, and no ordering is
defined between contexts.
Additionally, no synchronization is needed when accessing contexts in
parallel.
.PP
If the count is set to the value FI_SHARED_CONTEXT, the endpoint will be
configured to use a shared transmit context, if supported by the
provider.
Providers that do not support shared transmit contexts will fail the
request.
.PP
See the scalable endpoint and shared contexts sections for additional
details.
.SS rx_ctx_cnt - Receive Context Count
.PP
Number of receive contexts to associate with the endpoint.
If not specified, 1 context will be assigned if the endpoint supports
inbound transfers.
Receive contexts are independent processing queues that may be
separately configured.
Each receive context may be bound to a separate CQ, and no ordering is
defined between contexts.
Additionally, no synchronization is needed when accessing contexts in
parallel.
.PP
If the count is set to the value FI_SHARED_CONTEXT, the endpoint will be
configured to use a shared receive context, if supported by the
provider.
Providers that do not support shared receive contexts will fail the
request.
.PP
See the scalable endpoint and shared contexts sections for additional
details.
.SH SCALABLE ENDPOINTS
.PP
A scalable endpoint is a communication portal that supports multiple
transmit and receive contexts.
Scalable endpoints are loosely modeled after the networking concept of
transmit/receive side scaling, also known as multi-queue.
Support for scalable endpoints is domain specific.
Scalable endpoints may improve the performance of multi-threaded and
parallel applications, by allowing threads to access independent
transmit and receive queues.
A scalable endpoint has a single transport level address, which can
reduce the memory requirements needed to store remote addressing data,
versus using standard endpoints.
Scalable endpoints cannot be used directly for communication operations,
and require the application to explicitly create transmit and receive
contexts as described below.
.SS fi_tx_context
.PP
Transmit contexts are independent command queues.
Ordering and synchronization between contexts are not defined.
Conceptually a transmit context behaves similar to a send-only endpoint.
A transmit context may be configured with relaxed capabilities, and has
its own completion queue.
The number of transmit contexts associated with an endpoint is specified
during endpoint creation.
.PP
The fi_tx_context call is used to retrieve a specific context,
identified by an index.
Providers may dynamically allocate contexts when fi_tx_context is
called, or may statically create all contexts when fi_endpoint is
invoked.
By default, a transmit context inherits the properties of its associated
endpoint.
However, applications may request context specific attributes through
the attr parameter.
Support for per transmit context attributes is provider specific and not
guaranteed.
Providers will return the actual attributes assigned to the context
through the attr parameter, if provided.
.IP
.nf
\f[C]
struct\ fi_tx_ctx_attr\ {
\ \ \ \ uint64_t\ \ caps;
\ \ \ \ uint64_t\ \ mode;
\ \ \ \ uint64_t\ \ op_flags;
\ \ \ \ uint64_t\ \ msg_order;
\ \ \ \ size_t\ \ \ \ inject_size;
\ \ \ \ size_t\ \ \ \ size;
\ \ \ \ size_t\ \ \ \ iov_limit;
};
\f[]
.fi
.PP
\f[I]caps\f[] : The requested capabilities of the context.
The capabilities must be a subset of those requested of the associated
endpoint.
See the CAPABILITIES section if fi_getinfo(3) for capability details.
.PP
\f[I]mode\f[] : The operational mode bits of the context.
The mode bits will be a subset of those associated with the endpoint.
See the MODE section of fi_getinfo(3) for details.
.PP
\f[I]op_flags\f[] : Flags that control the operation of operations
submitted against the context.
Applicable flags are listed in the Operation Flags section.
.PP
\f[I]msg_order\f[] : The message ordering requirements of the context.
The message ordering must be the same or more relaxed than those
specified of the associated endpoint.
See the fi_endpoint Message Ordering section.
.PP
\f[I]inject_size\f[] : The requested inject operation size (see the
FI_INJECT flag) that the context will support.
This value must be equal to or less than the inject_size of the
associated endpoint.
See the fi_endpoint Inject Size section.
.PP
\f[I]size\f[] : The size of the context, in bytes.
The size is usually used as an output value by applications wishing to
track if sufficient space is available in the local queue to post a new
operation.
.PP
\f[I]iov_limit\f[] : This is the maximum number of IO vectors
(scatter-gather elements) that a single posted operation may reference.
.SS fi_rx_context
.PP
Receive contexts are independent command queues for receiving incoming
data.
Ordering and synchronization between contexts are not guaranteed.
Conceptually a receive context behaves similar to a receive-only
endpoint.
A receive context may be configured with relaxed endpoint capabilities,
and has its own completion queue.
The number of receive contexts associated with an endpoint is specified
during endpoint creation.
.PP
Receive contexts are often associated with steering flows, that specify
which incoming packets targeting a scalable endpoint to process.
However, receive contexts may be targeted directly by the initiator, if
supported by the underlying protocol.
Such contexts are referred to as \[aq]named\[aq].
Support for named contexts must be indicated by setting the caps
FI_NAMED_RX_CTX capability when the corresponding endpoint is created.
Support for named receive contexts is coordinated with address vectors.
See fi_av(3) and fi_rx_addr(3).
.PP
The fi_rx_context call is used to retrieve a specific context,
identified by an index.
Providers may dynamically allocate contexts when fi_rx_context is
called, or may statically create all contexts when fi_endpoint is
invoked.
By default, a receive context inherits the properties of its associated
endpoint.
However, applications may request context specific attributes through
the attr parameter.
Support for per receive context attributes is provider specific and not
guaranteed.
Providers will return the actual attributes assigned to the context
through the attr parameter, if provided.
.IP
.nf
\f[C]
struct\ fi_rx_ctx_attr\ {
\ \ \ \ uint64_t\ \ caps;
\ \ \ \ uint64_t\ \ mode;
\ \ \ \ uint64_t\ \ op_flags;
\ \ \ \ uint64_t\ \ msg_order;
\ \ \ \ size_t\ \ \ \ total_buffered_recv;
\ \ \ \ size_t\ \ \ \ size;
\ \ \ \ size_t\ \ \ \ iov_limit;
};
\f[]
.fi
.PP
\f[I]caps\f[] : The requested capabilities of the context.
The capabilities must be a subset of those requested of the associated
endpoint.
See the CAPABILITIES section if fi_getinfo(3) for capability details.
.PP
\f[I]mode\f[] : The operational mode bits of the context.
The mode bits will be a subset of those associated with the endpoint.
See the MODE section of fi_getinfo(3) for details.
.PP
\f[I]op_flags\f[] : Flags that control the operation of operations
submitted against the context.
Applicable flags are listed in the Operation Flags section.
.PP
\f[I]msg_order\f[] : The message ordering requirements of the context.
The message ordering must be the same or more relaxed than those
specified of the associated endpoint.
See the fi_endpoint Message Ordering section.
.PP
\f[I]total_buffered_recv\f[] : Defines the total available space
allocated by the provider to buffer received messages on the context.
This value must be less than or equal to that specified for the
associated endpoint.
See the fi_endpoint Total Buffered Receive section.
.PP
\f[I]size\f[] : The size of the context, in bytes.
The size is usually used as an output value by applications wishing to
track if sufficient space is available in the local queue to post a new
operation.
.PP
\f[I]iov_limit\f[] : This is the maximum number of IO vectors
(scatter-gather elements) that a single posted operating may reference.
.SH SHARED CONTEXTS
.PP
Shared contexts are transmit and receive contexts explicitly shared
among one or more endpoints.
A sharable context allows an application to use a single dedicated
provider resource among multiple transport addressable endpoints.
This can greatly reduce the resources needed to manage communication
over multiple endpoints by multiplexing transmit and/or receive
processing, with the potential cost of serializing access across
multiple endpoints.
Support for sharable contexts is domain specific.
.PP
Conceptually, sharable contexts are command queues that may be accessed
by many endpoints.
The use of a shared transmit context is mostly opaque to an application.
Applications must allocate and bind shared transmit contexts to
endpoints, but otherwise transmit operations are posted directly to the
endpoint.
An endpoint may only be associated with a single shared transmit
context.
.PP
Unlike shared transmit contexts, applications interact directly with
shared receive contexts.
Users post receive buffers directly to a shared receive context, with
the buffers usable by any endpoint bound to the shared receive context.
An endpoint may only be associated with a single receive context.
.PP
Endpoints associated with a shared transmit context may use dedicated
receive contexts, and vice-versa.
Or an endpoint may use shared transmit and receive contexts.
And there is no requirement that the same group of endpoints sharing a
context of one type also share the context of an alternate type.
Furthermore, an endpoint may use a shared context of one type, but a
scalable set of contexts of the alternate type.
.SS fi_stx_context
.PP
This call is used to open a sharable transmit context.
See fi_tx_context call under the SCALABLE ENDPOINTS section for details
on the transit context attributes.
The exception is that endpoints attached to a shared transmit context
must use a subset of the transmit context attributes.
This is opposite of the requirement for scalable endpoints.
.SS fi_srx_context
.PP
This allocates a sharable receive context.
See fi_rx_context call under SCALABLE ENDPOINTS section for details on
the receive context attributes.
The exception is that endpoints attached to a shared receive context
must use a subset of the receive context attributes.
This is opposite of the requirement for scalable endpoints.
.SH OPERATION FLAGS
.PP
Operation flags are obtained by OR-ing the following flags together.
Operation flags define the default flags applied to an endpoint\[aq]s
data transfer operations, where a flags parameter is not available.
Data transfer operations that take flags as input override the op_flags
value of an endpoint.
.PP
\f[I]FI_INJECT\f[] : Indicates that all outbound data buffer should be
returned to the user\[aq]s control immediately after a data transfer
call returns, even if the operation is handled asynchronously.
This may require that the provider copy the data into a local buffer and
transfer out of that buffer.
A provider may limit the total amount of send data that may be buffered
and/or the size of a single send.
Applications may discover and modify these limits using the
endpoint\[aq]s getopt and setopt interfaces.
.PP
\f[I]FI_MULTI_RECV\f[] : Applies to posted receive operations.
This flag allows the user to post a single buffer that will receive
multiple incoming messages.
Received messages will be packed into the receive buffer until the
buffer has been consumed.
Use of this flag may cause a single posted receive operation to generate
multiple completions as messages are placed into the buffer.
The placement of received data into the buffer may be subjected to
provider specific alignment restrictions.
The buffer will be freed from the endpoint when a message is received
that cannot fit into the remaining free buffer space.
.PP
\f[I]FI_BUFFERED_RECV\f[] : If set, the communication interface
implementation should attempt to queue inbound data that arrives before
a receive buffer has been posted.
In the absence of this flag, any messages that arrive before a receive
is posted are lost.
.PP
\f[I]FI_COMPLETION\f[] : Indicates that a completion entry should be
generated for data transfer operations.
.PP
\f[I]FI_REMOTE_SIGNAL\f[] : Indicates that a completion entry at the
target process should be generated for the given operation.
The remote endpoint must be configured with FI_REMOTE_SIGNAL, or this
flag will be ignored by the target.
The local endpoint must be configured with the FI_REMOTE_SIGNAL
capability in order to specify this flag.
.PP
\f[I]FI_REMOTE_COMPLETE\f[] : Indicates that local completions should
not be generated until the operation has completed on the remote side.
When set, if the target endpoint experiences an error receiving the
transferred data, that error will be reported back to the initiator of
the request.
This includes errors which may not normally be reported to the
initiator.
For example, if the receive data is truncated at the target because the
provided receive buffer is too small, the initiator will be notified of
the truncation.
.PP
\f[I]FI_READ\f[] : Indicates that the user wants to initiate reads
against remote memory regions.
Remote reads include some RMA and atomic operations.
.PP
\f[I]FI_WRITE\f[] : Indicates that the user wants to initiate writes
against remote memory regions.
Remote writes include some RMA and most atomic operations.
.PP
\f[I]FI_SEND\f[] : Indicates that the endpoint will be used to send
message data transfers.
Message transfers include base message operations as well as tagged
message functionality.
.PP
\f[I]FI_RECV\f[] : Indicates that the endpoint will be used to receive
message data transfers.
Message transfers include base message operations as well as tagged
message functionality.
.PP
\f[I]FI_REMOTE_READ\f[] : Indicates that the endpoint should allow
remote endpoints to read memory regions exposed by this endpoint.
Remote read operations include some RMA and atomic operations.
.PP
\f[I]FI_REMOTE_WRITE\f[] : Indicates that the endpoint should allow
remote endpoints to write to memory regions exposed by this endpoint.
Remote write operations include some RMA operations and most atomic
operations.
.SH NOTES
.PP
Users should call fi_close to release all resources allocated to the
fabric endpoint.
.PP
Endpoints allocated with the FI_CONTEXT mode set must typically provide
struct fi_context as their per operation context parameter.
(See fi_getinfo.3 for details.)
 However, when FI_COMPLETION is enabled to suppress completion entries,
and an operation is initiated without FI_COMPLETION flag set, then the
context parameter is ignored.
An application does not need to pass in a valid struct fi_context into
such data transfers.
.PP
Operations that complete in error that are not associated with valid
operational context will use the endpoint context in any error reporting
structures.
.SH RETURN VALUES
.PP
Returns 0 on success.
On error, a negative value corresponding to fabric errno is returned.
.PP
Fabric errno values are defined in \f[C]rdma/fi_errno.h\f[].
.SH ERRORS
.PP
\f[I]-FI_EDOMAIN\f[] : A resource domain was not bound to the endpoint
or an attempt was made to bind multiple domains.
.PP
\f[I]-FI_ENOCQ\f[] : The endpoint has not been configured with necessary
event queue.
.PP
\f[I]-FI_EOPBADSTATE\f[] : The endpoint\[aq]s state does not permit the
requested operation.
.SH SEE ALSO
.PP
\f[C]fi_getinfo\f[](3), \f[C]fi_domain\f[](3), \f[C]fi_msg\f[](3),
\f[C]fi_tagged\f[](3), \f[C]fi_rma\f[](3)
.SH AUTHORS
OpenFabrics.
