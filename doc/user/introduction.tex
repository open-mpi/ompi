% -*- latex -*-
%
% Copyright (c) 2004-2005 The Trustees of Indiana University.
%                         All rights reserved.
% Copyright (c) 2004-2005 The Trustees of the University of Tennessee.
%                         All rights reserved.
% Copyright (c) 2004-2005 High Performance Computing Center Stuttgart, 
%                         University of Stuttgart.  All rights reserved.
% Copyright (c) 2004-2005 The Regents of the University of California.
%                         All rights reserved.
% $COPYRIGHT$
% 
% Additional copyrights may follow
% 
% $HEADER$
%

\chapter{Introduction to Open MPI}
\label{sec:introduction}

This chapter provides a summary of the MPI standard and the
Open MPI implementation of that standard.

\section{About MPI}

The Message Passing Interface
(MPI)~\cite{geist96:_mpi2_lyon,mpi_forum93:_mpi}, is a set of API
functions enabling programmers to write high-performance parallel
programs that pass messages between processes to make up an
overall parallel job.  MPI is the culmination of decades of research
in parallel computing, and was created by the MPI Forum~-- an open
group representing a wide cross-section of industry and academic
interests.  More information, including the both volumes of the
official MPI standard, can be found at the MPI Forum web
site.\footnote{\url{http://www.mpi-forum.org/}}

MPI is suitable for ``big iron'' parallel machines such as the IBM SP,
SGI Origin, etc., but it also works in smaller environments such as a
group of workstations.  Since clusters of workstations are readily
available at many institutions, it has become common to use them as a
single parallel computing resource running MPI programs.
%
The MPI standard was designed to support portability and platform
independence.  As a result, users can enjoy cross-platform development
capability as well as transparent heterogenous communication.  For
example, MPI codes which have been written on the RS-6000 architecture
running AIX can be ported to a SPARC architecture running Solaris with
little or no modifications.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{About Open MPI}

Open MPI is a project combining technologies and resources from
several other projects (FT-MPI, LA-MPI, LAM/MPI, and PACX-MPI) in
order to build the best MPI library available.  A completely new MPI-2
compliant implementation, Open MPI offers advantages for system and
software vendors, application developers, and computer science
researchers.

Features implemented or in short-term development for Open MPI
include:

\begin{itemize}
\item Full MPI-2 standards conformance
\item Thread safety and concurrency
\item Dynamic process spawning
\item High performance on all platforms
\item Reliable and fast job management
\item Network and process fault tolerance
\item Support data and network heterogeneity
\item Single library supports all networks
\item Run-time instrumentation
\item Many job schedulers supported
\item Many OS's supported (32 and 64 bit)
\item Production quality software
\item Portable and maintainable
\item Tunable by installers and end-users
\item Extensive user and installer guides
\item Internationalized error messages
\item Component-based design, documented APIs
\item CPAN-like tool for component management
\item Active, responsive mailing list
\item Open source license based on the BSD license
\end{itemize}

The organizations (and newly-combined projects) contributing to Open
MPI are Indiana University (LAM/MPI), the University of Tennessee
(FT-MPI), and Los Alamos National Laboratory (LA-MPI). Additional
collaborators are at Sandia National Laboratories and the University
of Stuttgart. These developers bring many years of combined experience
to the project.

